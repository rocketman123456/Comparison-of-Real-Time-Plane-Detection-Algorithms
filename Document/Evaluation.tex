\documentclass[main.tex]{subfiles}
\begin{document}
% neue TOC:
% \begin{itemize}
%     \item DONE wie im konzept gesagt vergleichen wir algorithmen um \$FRAGE zu beantworten
%     \item DONE zunächst definieren wir, wie und woran wir die performanz der algos vergleichen
%     \begin{itemize}
%         \item DONE Wir werden die performanz an 3 metriken messen: P,R,F1 (siehe BG section)
%     \end{itemize}
%     \item wie im konzept festgestellt, sind die pdas nicht vergleichbar. daher haben wir 2 verschiedene datensätze rausgesucht und oder erstellt:
%     \begin{itemize}
%         \item 2D 3D S: statisch, direkt ganze wolke da
%         \item FIN: dynamisch, inkrementell aufbauend
%     \end{itemize}
%     \item wir führen experimente auf beiden datensätzen durch 
%     \item im anschluss werten wir die ergebnisse aus und evaluieren inwiefern die algorithmen echtzeitfähig sind
% \end{itemize}

\chapter{Evaluation}

In diesem kapitel werden zuvor ausgewählte algorithmen einheitlich verglichen und die resultierenden ergebnisse ausgewertet.
\section{Protocol}
% \begin{itemize}
%     \item was wir zeigen wollen
%     \item daher vergleichen wir algorithmen
%     \item wie vergleichen wir, woran ziehen wir schlüsse? 
% \end{itemize}
This work aims to determine which plane detection algorithm is the most suitable for an AR/VR system. For this decision, we uniformly compare the algorithms selected in
Chapter~\ref{chap:Concept}. We split the comparison into two experiments conducted on different datasets: the 2D-3D-S and the
self-created FIN dataset. Since both datasets are fundamentally different, we will perform the experiments and the analysis separately and then compare the results.
First, we present the metrics used for comparison, followed by an outline of the used configurations of parameters for each experiment.
% In this work, we perform a uniform comparison of plane detection algorithms. This comparison aims to evaluate the real-time plane 
% detection on off-the-shelf hardware through the selection of the best algorithm.
% In the following subsection, we present the metrics used for the evaluation.
% We conduct experiments on both datasets and compare the results of both experiments with respect to the real-time applicability of the
% algorithms. Particularly interesting are the differences resulting from the temporal component.
% Finally, by evaluating the results of both experiments, we determine the most suitable plane detection algorithm for real-time, indoor environments. 

\subsection{Metrics}
\label{subsec:metrics}
\paragraph{Accuracy}
To quantify the accuracy of the plane detection algorithms, we use the detected planes and the created ground truth to calculate the three following
metrics: Precision, Recall, and the F1-score. The procedure of calculation is taken from~\cite[Section~4]{Araújo_Oliveira_2020} and detailed
in Section~\ref{sec:metrics}.


\textcolor{red}{hier noch mehr ins detail gehen? (antwort) \underline{\hspace{2cm}}}

\paragraph{Time Measurements}
\label{par:time}
In addition to the accuracy, we are interested in the real-time applicability of an algorithm. We present two definitions
of \textit{real-time} in Section~\ref{sec:realtime}. 
Da wir zwei Definitionen von echtzeit haben, ist es sinnvoll, auch zwei Metriken der Berechnungszeiten einzuführen.
Dazu, um präzise Aussagen über die Laufzeiten der algorithmen treffen zu können, teilen wir die Berechnung in 
pre-processing, plane calculation, und post-processing auf. Die jeweiligen Berechnungszeiten werden im Folgenden als
$t_{pre}, t_{calc}$ und $t_{post}$ bezeichnet. Neben präzisen Aussagen ermöglicht uns diese Aufteilung auch zu bestimmen,
ob ein Algorithmus $RT_{calc}$ ist. Um zu bestimmen, ob ein Algorithmus $RT_{tot}$ ist, werden wir dazu die totale 
Berechnungszeit $t_{tot}$ angeben, welche sich aus der Summe der individuellen Zeiten ergibt:

\begin{equation}
    t_{tot} = t_{pre} + t_{calc} + t_{post}
\end{equation}

\textbf{\textcolor{red}{das hier eher in den BG oder?}}
RSPD and OPS perform an initial estimation of normals, while 3D-KHT and OBRG construct an octree during their
pre-processing phase. Note, that the octree construction of OBRG includes a local estimation of normals on the
leaf level. OPS merges smaller planes if they pass a coplanarity test and then re-estimates the normals of the
resulting plane. In the post-processing step, OBRG refines the borders of detected planes by inserting
previously unallocated regions.
The pre-and post-processing steps are summarized in Table~\ref{tab:pre-post}.

\textbf{\textcolor{red}{\#detected planes als metrik einführen? ist imho wenig aussagekräftig da die GT erstellung so subjektiv ist}}

\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
             & RSPD        & OPS        & 3D-KHT         & OBRG           \\ \hline
        Pre  & Normal est. & Normal est & Octree constr. & Octree constr. \\
        Post & /           & Merge      & /              & Refinement
    \end{tabular}
    \caption{Pre-processing and post-processing steps of the plane detection algorithms. RSPD and 3D-KHT do not have any post-processing steps.}
    \label{tab:pre-post}
\end{table}


\subsection{Parameterization of Algorithms}
Because the datasets inherit different amounts of noise, it is necessary to modify the algorithms accordingly.
We thereby modify the algorithms' parameterization to achieve more noise robustness.
In the following, the parameterizations of the algorithms with respect to the two experiments are outlined.
Therein, we refer to the parameterization of the 2D-3D-S experiment as the default configuration.
All deviations from this default configuration necessary for the FIN experiment are determined empirically.


\subsubsection{RSPD}
\textbf{\textcolor{red}{die abkürzungen werden sicherlich im BG erklärt.}}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccc}
        Experiment & $l_O$ & $\varepsilon$ & MOR  & $k$ & MND & MDP   \\ \hline
        2D-3D-S    & 10    & 30            & 25\% & 30  & 60° & 0.258 \\
        FIN        & 10    & 30            & 25\% & 30  & 60° & 0.258
    \end{tabular}%
    \caption{Parameter configuration of RSPD used for the experiments.}
    \label{tab:rspd-param}
\end{table}

% FIXME overwork this paragraph given the newly obtained knowledge.
\paragraph{2D-3D-S}
For the 2D-3D-S experiment, we use the parameters of the provided implementation. These parameters include the maximum octree level $l_O$,
the minimum number of samples per leaf node $\varepsilon$, the maximum percentage of outliers per plane $\theta_{outlier}$, and
the size of the nearest neighborhood $k$. Note that while $k=50$ is used in the respective paper~\cite[Section~3.3]{Araújo_Oliveira_2020},
we use $k=30$ because, in our experience, it produces sufficient results while reducing the pre-processing time.

\paragraph{FIN}
\textbf{\textcolor{red}{Da bei der erstellung von rspd besonders auf noise resistenz geachtet wurde, passen wir keinen parameter für
        das FIN experiment an.
        Es wurden diverse anpassungen getestet, keine davon haben jedoch die ergebnisse verbessert.}}
\subsubsection{OPS}

\textcolor{red}{ja, die parameter werden im background \textit{sicherlich} erklärt}
\begin{table}[H]
    \centering
    \begin{tabular}{c|ccccc}
        Experiment & $\alpha_s$ & $KNN$       & $\theta_{h}$  & $\theta_{N}$ & $p$  \\ \hline
        2D-3D-S    & 3\%        & 30          & 0.05          & 100          & 0.99 \\
        FIN        & 3\%        & \textbf{90} & \textbf{0.35} & 100          & 0.99
    \end{tabular}%
    \caption{Parameter configuration of OPS used for the experiments.}
    \label{tab:ops-param}
\end{table}

\paragraph{2D-3D-S}
The parameter configuration used for the 2D-3D-S experiment is shown in the first row of Table~\ref{tab:ops-param}.
We use a sampling rate $\alpha_s$ of 3\% and a neighborhood $KNN$ of 30 for the estimation of normal vectors.
Additionally, we use a distance threshold $\theta_h$ of 0.05(m).
Furthermore, we set the inlier threshold $\theta_N$ to 100 and the probability for adaptively determining RANSAC iterations
$p$ to $0.99$, as proposed in~\cite[Section~4A]{Sun_Mordohai_2019}.

\paragraph{FIN}
For the FIN experiment, we increase $KNN$ to 90, as larger neighborhood sizes increase the accuracy of normal estimation and,
consequently, the overall accuracy of a method.
Furthermore, we increase the tolerated plane thickness $\theta_h$ because an increase in sensor noise ultimately thickens the recorded planes.
Both modifications are highlighted in bold in the second row of Table~\ref{tab:ops-param}.

\subsubsection{3D-KHT}
\begin{table}[H]
    \centering
    \begin{tabular}{c|ccccccc}
        Experiment & $\phi_{num}$ & $\rho_{num}$ & $s_{level}$ & $s_{ps}$ & $d_{max}$    & $s_\alpha$ & $s_\beta$ \\ \hline
        2D-3D-S    & 30           & 200          & 2           & 0.002    & 0.08         & 18         & 6         \\
        FIN        & 30           & \textbf{100} & 2           & 0.002    & \textbf{0.1} & \textbf{8} & 6
    \end{tabular}%
    \caption{Parameter configuration of 3D-KHT used for the experiments.}
    \label{tab:3dkht-param}
\end{table}

\paragraph{2D-3D-S}
The parameter configuration is shown in Table~\ref{tab:3dkht-param}. We use an accumulator discretization of 30 and 200 for $\phi$ and $\rho$, respectively.
Starting to check for planarity at an octree level $s_{level}$ of 2 seems to yield the best results.
\citeauthor{Limberger_Oliveira_2015}~\cite{Limberger_Oliveira_2015} propose
a minimum of 30 samples per cluster, however, we use $0.2\%$ of the total point cloud due to the wide ranges of point cloud sizes in the dataset (see Subsection~\ref{subsec:bg-stanford}).
Lastly, we set $s_\beta$ to 6, as proposed in~\cite[Section~3.1]{Limberger_Oliveira_2015}. In contrast, using a $s_\alpha$ value of 18 seemed to yield better results than the proposed 25.
% FIXME im background sicher gehen dass ich die erklärt habe

\paragraph{FIN}
For the FIN experiment, we modify the values of $\rho_{num}$, $d_{max}$ and $s_\alpha$ to accommodate for the higher levels of noise.
Reducing $\rho_{num}$ should decrease the accuracy, however, it seems to yield better results in a high-noise environment like the FIN dataset.
We increase $d_{max}$ and decrease $s_\alpha$ to allow for slightly thicker, e.g. noisier, planes to be detected.
The modification of parameters is highlighted in bold in Table~\ref{tab:3dkht-param}.

\subsubsection{OBRG}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccc}
        Experiment & $l_{max}$ & $\theta_{res}$ & $\theta_{d}$ & $\theta_{ang}$ & $\theta_M$ & $\theta_p$    \\ \hline
        2D-3D-S    & 5         & 0.08           & 0.08         & 0.18           & 5000       & 90\%          \\
        FIN        & 5         & \textbf{0.22}  & \textbf{0.2} & \textbf{0.2}   & 5000       & \textbf{70\%}
    \end{tabular}
    \caption{Parameter configuration of OBRG used for the experiments.}
    \label{tab:obrg-param}
\end{table}

% FIXME boldness in tables in der caption erläutern

\paragraph{2D-3D-S}
The used configurations for the experiments are shown in Table~\ref{tab:obrg-param}.
Due to the low level of noise, we assign a very small tolerance to $\theta_{res}$ and $\theta_d$. Additionally, we assign a high
planarity threshold value of $\theta_p = 90\%$.

\paragraph{FIN}
Due to higher levels of noise, and thus, thicker walls, we increase the residual threshold $\theta_{res}$, the distance
threshold $\theta_d$, and the angular divergence threshold $\theta_{ang}$. According to~\cite[Section~3.4]{Vo_Truong-Hong_Laefer_Bertolotto_2015},
the planarity threshold $\theta_p$ should be chosen between 70\% and 90\% depending on the noise level. As the expected noise level of the
FIN dataset is much higher than the noise of the 2D-3D-S dataset, we reduce this threshold to 70\%.
The used parameters for the FIN experiment are summarized in the second row of Table~\ref{tab:obrg-param}.


\section{Results}
This section deals with the results of the experiments. 
The individual results of both experiments are presented and analyzed. Lastly, the results are compared.

\textbf{\textcolor{red}{this still seems poorly placed}}
In einer echten Umgebung wachsen die Punktwolken inkrementell über Zeit. 
Die Angabe von Durchschnittswerten der Berechnungszeiten ist daher nur bedingt aussagekräftig, da diese bei anfänglichen Zeitschritten 
kürzer sein werden, als am Ende der Aufnahme. Wir werden daher neben Durchschnittswerten der Berechnungszeiten auch 
den Zusammenhang zwischen der Größe der Punktwolke und der Dauer der Berechnung betrachten.

\subsection{2D-3D-S}

Wir haben RSPD, OPS, 3D-KHT und OBRG auf 139 Scenen des 2D-3D-S Datensatzes laufen lassen. Im Anschluss wurden zu jeder Scene die Präzision,
der Recall und der F1-Score von jedem Algorithmus berechnet. Dazu wurden die Berechnungszeiten gemessen und in pre-processing, plane detection und
post-processing aufgeteilt. Die rechteste Spalte gibt die totale Berechnungszeit $t_{tot}$ an. Table~\ref{tab:res-3d2ds-total} zeigt die average der berechneten Ergebnisse zu jedem Algorithmus. Durch dicke Schrift
werden die besten durchschnittswerte hervor gehoben. Für precision, recall und f1 sind die größten Werte dick geschrieben. Für alle zeitlichen
Ergebnisse ist der geringste Wert durch dicke Schrift hervor gehoben. Dazu sei anzumerken, dass kein niedrigster wert von $t_{post}$ angedeutet 
wird, da RSPD und 3D-KHT keine post-processing schritte haben und daher "per default" weniger zeit in diesem Schritt verbringen.

\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccc|c}
        Algorithm & Precision        & Recall           & F1-Score         & $t_{pre}$     & $t_{calc}$    & $t_{post}$ & $t_{tot}$     \\ \hline
        RSPD      & 84.80\%          & \textbf{89.79\%} & \textbf{86.84\%} & 62.65         & 1.04          & /          & 63.69         \\
        OPS       & \textbf{88.98\%} & 70.45\%          & 77.68\%          & 13.12         & 10.97         & 1.01       & 25.10         \\
        3DKHT     & 71.40\%          & 78.32\%          & 75.19\%          & \textbf{0.71} & \textbf{1.03} & /          & \textbf{1.74} \\
        OBRG      & 81.38\%          & 66.77\%          & 71.00\%          & 28.07         & 34.29         & 2.61       & 62.97
    \end{tabular}
    \caption[Overall 2D-3D-S Results]{Average results of each algorithm over the 2D-3D-S dataset. The right half of the inner columns shows the average time spent in
        pre-processing ($t_{pre}$), the average time spent in the plane detection ($t_{calc}$), and the average time spent in post-processing steps ($t_{post}$).
        Note, that the absence of post-processing steps is denoted as "/". All times are measured in seconds.}
    \label{tab:res-3d2ds-total}
\end{table}

\paragraph{Accuracy}
Mit einer Präzision von ca. 85\%, einem Recall von ca. 90\% und einem F1-Score von ca. 87\% ist RSPD der insgesamt präziseste algorithmus.
OPS übertrifft RSPD zwar in der Precision mit einem Wert von ca. 89\%, erzielt dafür aber deutlich geringere Recall und F1-Score Ergebnisse.
3D-KHT erzielt Ergebnisse mit einer Precision, Recall und F1-Score im Bereich zwischen ca. 71\% und ca. 79\%.
OBRG erreicht zwar eine hohe Präzision mit ca 81\%, erzielt aber schlussendlich die niedrigsten Recall und F1-Score Werte unter den Algorithmen mit
67\%, bzw. 71\%.

\paragraph{Average Time }
\label{par:2D-3D-S-time}
3D-KHT scores the lowest processing times. With an average of 0.71 seconds spent in pre-processing, and an average of 1.03 seconds spent in plane detection,
3D-KHT only needs an average total of 1.74 seconds to process an entire point cloud. RSPD is the only algorithm that scores similar $t_{calc}$ values, with an
average of 1.04 seconds. However, RSPD's time spent in pre-processing is the highest among the algorithms.
With an average $t_{tot}$ of ca. 25 seconds and ca. 63 seconds, OPS and OBRG, respectively, run dramatically slower than the other two algorithms.

\paragraph{Relationship of Time and Size}
As stated in Paragraph~\ref{par:time}, it is useful to consider the relationship between the computation times and the amount of
processed data. For each scene of the 2D-3D-S dataset, the pairs of 
processing times and point cloud file sizes are presented in Figure~\ref{fig:sizetimestanford}. Note, that the most scenes have a 
file size of under $50mb$.


Die pre-processing Zeiten von RSPD, OPS und OBRG scheinen ein lineares Verhältnis zu der File size zu haben. 3D-KHT hat als einziger Algorithmus
ein logarithmisches Wachstum bei den pre-processing zeiten.

Der Verlauf von $t_{calc}$ bei 3D-KHT und RSPD ist sehr ähnlich, was die durchschnittswerte aus Tabelle~\ref{tab:res-3d2ds-total} bestätigt.
Beide Laufzeiten scheinen ein sehr geringes, lineares Wachstum in Abhängigkeit zur Dateigröße zu haben.

The plane detection step of OPS seems to be somewhat dependent on the file size. However, the distinct processing times 
seem to fluctuate more in comparison to 3D-KHT and RPSD, which can be seen by the vertical broadness of the yellow graph.
The $t_{calc}$ values of OBRG also show fluctuations, however, the range is larger compared to OPS. 
Overall, the time OBRG spent in plane detection does not seem to depend directly on the size of the processed point cloud.

3D-KHT and RSPD do not have post-processing steps, hence the absence in their respective subfigures. 
The post-processing times of OPS seem to be primarily negligible, given the narrow spikes. On the other hand, the post-processing times
of OBRG seems to be somewhat stable around $10^0s$, with a few exceptions, e.g. $t_{post}=10^{-2}s$ at a file size of ca. 130.
\textbf{\textcolor{red}{wenn log scale und graph grade, sag ich dann dass das wachstum logarithmisch oder linear ist?}}


\begin{figure}[H]
    \centering
    % \includegraphics[width=\textwidth]{images/time_size_2d3ds.png}
    \includegraphics[width=\textwidth]{images/SDsizetime.png}
    \caption[Time per Cloud size 2D-3D-S]{Time spent in pre-processing ($t_{pre}$), plane detection ($t_{calc}$), 
    and post-processing ($t_{post}$) per point cloud file size of the 2D-3D-S dataset. Note, that the y-axis is 
    scaled logarithmically to the base of ten.}
    \label{fig:sizetimestanford}
\end{figure}


\paragraph{Summary 2D-3D-S Experiment}
OPS hat den größten Wert in Precision, während RSPD die höchste Accuracy und den größten F1-Score erzielt.
3D-KHT hat mit durchschnittlich $1.74s$ die geringste total Berechnungszeit $t_{tot}$. RSPD und OBRG haben mit mehr als 60 sekunden
die größten $t_{tot}$ Werte unter den Algorithmen, wobei $t_{pre}$ bei RSPD den großteil ausmacht.

Figure~\ref{fig:sizetimestanford} zeigt, dass die Laufzeiten von 3D-KHT am geringsten sind. RSPD hat ebenfalls geringe $t_{calc}$ Werte,
verbringt jedoch die durchweg längste Zeit im pre-processing.
Ferner scheinen die pre-processing Zeiten aller algorithmen im allgemeinen von der Größe der Punktwolke abhängig zu sein.
Die plane detection Laufzeiten von OPS und OBRG fluctuieren, OPS weniger als OBRG. 
Die post-processing Laufzeiten von OPS sind insgesamt zu vernachlässigen, bei OBRG, mit ausnahme von ausreissern bei mittleren Dateigrößen,
 stabil bei durchschnittlich $2.61s$, siehe Tabelle~\ref{tab:res-3d2ds-total}.     

\subsection{FIN}
Jeder der insgesamt 732 Zeitschritte des FIN Datensatzes wurde von jedem algorithmus verarbeitet. Im Anschluss wird
jeder Zeitschritt seperat ausgewertet, also die Präzision, der Recall und der F1-Score berechnet. Dazu
wurden, wie beim 2D-3D-S Experiment die Berechnungszeiten der Algorithmen für jeden Zeitschritt gemessen.
Die durchschnittlichen Ergebnisse über alle Zeitschritte aller Scenen des FIN Experiments werden
in Table~\ref{tab:res-fin-total} präsentiert. Für precision, recall und den f1-score sind die höchsten werte dick geschrieben.
Die niedrigsten Zeiten jedes Berechnungsschritts sind ebenfalls durch dicke schrift gehighlighted.


\begin{table}[H]
    \centering
    \begin{tabular}{c|cccccc|c}
        Algorithm & Precision        & Recall           & F1-Score         & $t_{pre}$     & $t_{calc}$    & $t_{post}$ & $t_{tot}$     \\ \hline
        RSPD      & 57.30\%          & \textbf{60.75\%} & \textbf{58.70\%} & 14.36         & \textbf{0.19} & /          & 14.55         \\
        OPS       & \textbf{69.38\%} & 29.23\%          & 39.43\%          & 4.61          & 0.89          & 0.13       & 5.63          \\
        3DKHT     & 49.76\%          & 44.40\%          & 46.48\%          & \textbf{0.14} & 0.29          & /          & \textbf{0.43} \\
        OBRG      & 49.23\%          & 27.42\%          & 33.94\%          & 6.03          & 14.70         & 0.35       & 21.08
    \end{tabular}
    \caption[Average FIN Results]{Average Results of the FIN experiment. Shown are the average values of all scenes and time frames, sorted by
        algorithm. The right half of the columns shows the average time spent in pre-processing ($t_{pre}$), the average time spent in the plane
        detection itself ($t_{calc}$), and the average time spent in post-processing steps ($t_{post}$).
        Note, that the absence of post-processing steps is denoted as "/".}
    \label{tab:res-fin-total}
\end{table}

\paragraph{Accuracy}
OPS hat mit nahezu 70\% die höchste Durschnittspräzision der Algorithmen. RSPD hat dafür mit ca. 60\% die jeweils höchsten
Werte für Recall und F1-Score erzielt. 3D-KHT und OBRG erzielen ähnliche Ergebnisse der precision, bei Recall und
F1-Score hat 3D-KHT jedoch um ca. 13\%, bzw. ca. 17\% höhere Werte als OBRG.

\paragraph{Average Time}
RSPD braucht unter den algorithmen die meiste Zeit im pre-processing. Im kontrast dazu hat RSPD mit 0.19 sekunden
die kürzeste Zeit, die in der plane detection verbracht wird. Insgesamt braucht 3D-KHT mit durchschnittlich $0.43$
sekunden jedoch am kürzesten für die komplette Berechnung $t_{tot}$ eines Zeitschritts. OPS erzielt mit ca. 6 sekunden vergleichsweise
durchschnittliche Zeiten und OBRG braucht mit mehr als 20 sekunden insgesamt am längsten für die Berechnung
eines Zeitschritts.

\paragraph{Relationship of Time and Size}
Wie auch in Paragraph~\ref{par:2D-3D-S-time} möchten wir den zusammenhang zwischen der Menge an Daten und den Zeiten
der Berechnung von ihnen betrachten.
In Figure~\ref{fig:dynaudi} werden die Dauer der Berechnung jedes Zeitschritts der Dateigröße von der
\textit{auditorium} Scene des FIN Datensatzes gegenüber gestellt. \textbf{\textcolor{red}{Dazu sei gesagt, dass vergleichbare grafiken
für die anderen Scenen des FIN Datensatzes erstellt wurden. Sie stellen argumentativ keine neuen informationen dar und werden 
vollständigkeitshalber und aus platzgründen im anhang \$REF präsentiert. Es wurde sich hier für die Auditorium Scene
entschieden, da diese die längste Aufnahme darstellt, und damit die meisten Daten beinhaltet.}}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/dyn_time-audi.png}
    \caption[Time Results Hallway]{Time spent in pre-processing (blue), plane detection (yellow), and post-processing
        (green) of the hallway scene and cloud sizes (red) of each time step. Note, that both y-axes are scaled 
        logarithmically to the base of ten}
    \label{fig:dynaudi}
\end{figure}


Bei RSPD und OBRG kann man direkt sehen, dass die pre-processing zeiten $t_{pre}$ proportional zur größe der punktwolke
sind. Im kontrast dazu scheinen bei OPS und 3D-KHT die pre-processing zeiten mehr mit den Zeiten der plane detection
$t_{calc}$ in Verbindung zu stehen. Bei RSPD, OPS und 3D-KHT scheint $t_{calc}$ unabhängig von der Größe der Punktwolke
zu sein und befindet sich stets unter einem gewissen Wert. Einzig auffallend ist das rapide Wachstum von OBRG im zeitraum
vom Start bis ca. 25.
Finally, the time spent in post-processing of OPS and OBRG is negligible as both times seem to stay at a constant
value.

\paragraph{Summary FIN Experiment}
OPS hat die höchste Durchschnittspräzision, RSPD hat die größten Prozente in Recall und F1-Score. Auch in der plane detection
hat RSPD mit durchschnittlichen $0.19s$ den geringsten $t_{calc}$ Wert unter den Algorithmen. Im kontrast dazu hat RSPD 
den längste Dauer des pre-processing mit $14.36s$ im Durchschnitt. Der algorithmus mit der Kürzesten pre-processing, sowie
totalen Zeit ist 3D-KHT mit $t_{pre}=0.14$, bzw. $t_{sum}=0.43$.

Die Berechnungszeiten von RSPD scheinen proportional zur Größe der Punktwolke, das gleiche gilt für OBRG. 
Dabei wächst bei RSPD $t_{pre}$ deutlich schneller als $t_{calc}$. Im kontrast dazu scheinen die pre-processing
und plane detection Zeiten von OBRG am Ende der Aufnahme sich bei einen gemeinsamen Wert zu treffen.  
Die Berechnungszeiten von OPS scheinen unabhängig von der Größe der Punktwolke zu sein, dafür aber eher voneinander. 
Wie OPS scheint das Wachstum der Punktwolke keinen Einfluss auf die Berechnungszeiten von 3D-KHT zu haben, die totale 
Berechnungszeit einer Punktwolke ist konstant unter einer sekunde.

\subsection{Comparison}
When comparing Table~\ref{tab:res-3d2ds-total} and Table~\ref{tab:res-fin-total}, a pattern emerges:
OPS has the highest precision value, RSPD yields the highest Recall and F1-Score, and 3D-KHT has the lowest 
average total processing time.

Wenn man sich Figure~\ref{fig:dynaudi} and Figure~\ref{fig:sizetimestanford} ansieht, fallen auch gemeinsamenkeiten auf:
Der Kurvenverlauf von RSPD ist in beiden Experimenten praktisch identisch, ist proportional zur Größe der Punktwolke 
und die pre-processing Zeit stellt 99\% der totalen Berechnungszeit dar.
Eine andere gemeinsamkeit ist, dass die post-processing Zeiten von OPS sehr fluktuiert. Bei OBRG scheint die Dauer des 
post-processings bis zu einer Punktwolken Größe von ca. $80mb$ vergleichsweise stabil um einen geringen Wert zu sein.

Es gibt aber auch Unterschiede. Im Vergleich zum 2D-3D-S Experiment verhalten sich die Laufzeiten von 3D-KHT beim 
FIN experiment nicht proportional zur Größe der Punktwolke. Dazu sei gesagt,dass die maximale Größe im FIN experiment
bei ca. $30mb$ liegt, was natürlich deutlich kleiner als das maximum des 2D-3D-S Datensatzes ($>400mb$) ist.
Da in Figure~\ref{fig:sizetimestanford} aber auch für kleinere Wolken eine proportionalität zu erkennen ist, wird 
der grund für die verschiedenen Verläufe wahrscheinlich die unterschiedliche Parametrisierung sein.


\section{Summary}

RSPD hat in beiden Experimenten insgesamt die höchsten Accuracy Werte. Dazu hat RSPD den größten $t_{pre}$
Wert in beiden Experimenten und den kleinsten $t_{calc}$ Durschnittswert im FIN Experiment. 
3D-KHT hat in beiden Experiment die geringste totale Berechnungszeit und übertrifft im 2D-3D-S Experiment die 
plane detection Zeit von RSPD.

% NOTE 3DKHT kann keine löcher oder non-rectangular ebenen basteln!


\end{document}